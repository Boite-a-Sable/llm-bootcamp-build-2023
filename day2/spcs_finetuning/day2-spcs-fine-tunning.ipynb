{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b1710c-d5d9-4dcc-954e-2938ad1f32cf",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 2\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876bbda5-b330-4d71-a335-ac178274b6ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /opt/conda/envs/rapids/lib/python3.8/site-packages (0.6.2)\n",
      "Requirement already satisfied: transformers==4.34.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (4.34.0)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/envs/rapids/lib/python3.8/site-packages (0.14.1)\n",
      "Requirement already satisfied: vllm==0.2.1.post1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (0.2.1.post1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/envs/rapids/lib/python3.8/site-packages (0.41.2.post2)\n",
      "Requirement already satisfied: datasets in /opt/conda/envs/rapids/lib/python3.8/site-packages (2.14.7)\n",
      "Requirement already satisfied: absl-py==1.3.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (23.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (2023.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (4.65.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (0.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (1.23.5)\n",
      "Requirement already satisfied: pydantic<2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (1.10.7)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (5.9.4)\n",
      "Requirement already satisfied: ninja in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (1.11.1.1)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (2.0.1)\n",
      "Requirement already satisfied: fastapi in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (0.86.0)\n",
      "Requirement already satisfied: ray>=2.5.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (2.8.0)\n",
      "Requirement already satisfied: uvicorn[standard] in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (0.21.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (1.5.3)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (10.0.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (0.1.99)\n",
      "Requirement already satisfied: xformers==0.0.22 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (0.0.22)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (11.7.91)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (11.10.3.66)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (1.12)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (11.7.101)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (11.4.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->vllm==0.2.1.post1) (67.6.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/rapids/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->vllm==0.2.1.post1) (0.40.0)\n",
      "Requirement already satisfied: lit in /opt/conda/envs/rapids/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1->vllm==0.2.1.post1) (17.0.5)\n",
      "Requirement already satisfied: cmake in /opt/conda/envs/rapids/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1->vllm==0.2.1.post1) (3.27.7)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from peft) (0.24.1)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (8.1.3)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (4.21.12)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (4.17.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (1.0.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->transformers==4.34.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->transformers==4.34.0) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->transformers==4.34.0) (1.26.15)\n",
      "Requirement already satisfied: starlette==0.20.4 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from fastapi->vllm==0.2.1.post1) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from starlette==0.20.4->fastapi->vllm==0.2.1.post1) (3.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from pandas->vllm==0.2.1.post1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from pandas->vllm==0.2.1.post1) (2023.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (0.14.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (0.19.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (10.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->vllm==0.2.1.post1) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jinja2->torch==2.0.1->vllm==0.2.1.post1) (2.1.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (5.12.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from sympy->torch==2.0.1->vllm==0.2.1.post1) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi->vllm==0.2.1.post1) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (3.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install peft transformers==4.34.0 tokenizers vllm==0.2.1.post1 bitsandbytes datasets absl-py==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d875a77-e12b-4fb7-bbef-e54e8b2113b8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fb24a1-da33-43e2-9924-c9ccae223717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import sys\n",
    "from ft_datasets.utils import Concatenator\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import os\n",
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "from transformers import default_data_collator, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306b93f-c225-40ea-8480-10739c887b4d",
   "metadata": {},
   "source": [
    "### Load Base Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21622331-74b3-48b7-9b8f-5f1b7fba3e74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer\n",
      "loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d25ebd7b6014806a91ee9b041dc453b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "print('loading tokenizer')\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "print('loading model')\n",
    "model =LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a142a-182d-4a10-a92d-85410828226a",
   "metadata": {},
   "source": [
    "## Prepare Datasets\n",
    "### Load Datasets\n",
    "\n",
    "*NOTE: Fine-tuning using 100 records on this setup (compute and other resources) will take about ~5mins and on the entire dataset it will take over 1 hour.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c1c2df6-84e2-4f5d-a019-4a31625e65bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b448d2bc662c4f28b4cba5f9e1f28334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not run this cell in the live demo, it takes >20 minutes to run\n",
    "\n",
    "# def prepare_stratified_dataset(path, seed = 42):\n",
    "#     raw_df = pd.read_json(path, lines=True)\n",
    "#     raw_df['id'] = raw_df.index\n",
    "#     ds = Dataset.from_pandas(raw_df, split='train')\n",
    "#     cl = ClassLabel(num_classes=4, names=[\"EN\", \"FR\", \"DE\", \"ES\"])\n",
    "#     new_features = ds.features.copy()\n",
    "#     new_features['lang_label'] = cl\n",
    "#     cl_d = {l : cl.str2int(l) for l in [\"EN\", \"FR\", \"DE\", \"ES\"]}\n",
    "#     def convert_lang(sample):\n",
    "#         sample['lang_label'] = cl_d[sample['language']]\n",
    "#         return sample\n",
    "#     ds = ds.map(convert_lang, features=new_features)\n",
    "#     ds_split = ds.train_test_split(test_size=0.15, stratify_by_column='lang_label', seed=42)\n",
    "#     test_ds_split = ds_split['test'].train_test_split(test_size=2/3, stratify_by_column='lang_label', seed=42)\n",
    "#     return ds_split['train'].to_pandas(), test_ds_split['train'].to_pandas(), test_ds_split['test'].to_pandas()\n",
    "\n",
    "# train_df, eval_df, test_df = prepare_stratified_dataset(\n",
    "#     '../transcripts.json'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ce0d6a-52f8-4a98-bb64-dffd9de39f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 1368\n",
      "Train        : 100\n",
      "Eval         : 100\n",
      "Test         : 100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"../transcripts.json\", lines=True)\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "train_df = df.head(100)\n",
    "print(f\"Train        : {train_df.shape[0]}\")\n",
    "eval_df = df[200:300]\n",
    "print(f\"Eval         : {eval_df.shape[0]}\")\n",
    "test_df = df.tail(100)\n",
    "print(f\"Test         : {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48eb4986-85f7-4465-b56c-ef35f7edfa95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>language</th>\n",
       "      <th>id</th>\n",
       "      <th>lang_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"frosty: Greetings! I'm Frosty, your voice bot assistant for the holiday season. What's your name?\\ncaller: Hey Frosty, my name is James.\\nfrosty: Hi James! Where are you calling from?\\ncaller: I'm calling from Sydney.\\nfrosty: Nice to meet you, James from Sydney! Let's get started with your holiday wish list. What toy would you like to choose?\\ncaller: Hmm... I'm not sure yet. What do you recommend?\\nfrosty: I'm happy to help you explore our catalog! Does your child like plush toys?\\ncaller: Yes, my little one definitely loves plush toys.\\nfrosty: We have a sweet 2023 Holiday Fox 12-Inch Plush, or how about the Sesame Street Monster Meditation Elmo? Both are soft and cuddly.\\ncaller: Oh, Elmo for sure!\\nfrosty: The Sesame Street Monster Meditation Elmo is an excellent choice. Tell me, what do you enjoy the most about this time of the year?\\ncaller: I love seeing all the decorations and spending time with my family.\\nfrosty: That's wonderful! Do you have any favorite holiday memories?\\ncaller: One year, we had a fantastic snowball fight in the park with our friends. It was so much fun!\\nfrosty: That sounds like a terrific memory! So, are we adding Sesame Street Monster Meditation Elmo to your wish list?\\ncaller: Yes! And you know what? Add the fox plushie as well.\\nfrosty: You got it, adding the 2023 Holiday Fox 12-Inch Plush and Sesame Street Monster Meditation Elmo to your wish list. Have a great holiday season, James!\\ncaller: Thanks, Frosty! You too!\"</td>\n",
       "      <td>{\"toy_list\": [\"2023 Holiday Fox 12-Inch Plush\", \"Sesame Street Monster Meditation Elmo\"], \"location\": \"Sydney\"}</td>\n",
       "      <td>EN</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi there!\\nfrosty: Hello! Welcome to our holiday hotline, I'm Frosty. How can I assist you today?\\ncaller: Hey, Frosty. My name is Mike, and I live in Los Angeles.\\nfrosty: Hi, Mike from Los Angeles! What can I help you with?\\ncaller: I want to submit my holiday wish list, but I'm not sure what toys my son would like.\\nfrosty: No problem! I'd be happy to help you explore our catalog. What are some of his interests?\\ncaller: He loves playing with new gadgets and is a fan of Star Wars.\\nfrosty: How about Star Wars LOLA animatronic droid? It's a fun gadget for any Star Wars fan.\\ncaller: That sounds interesting. What else do you have?\\nfrosty: Another option could be a Dog-E, the robot dog. It's a popular gadget for kids this holiday season.\\ncaller: Let's go with the lola droid. But I also need a second toy.\\nfrosty: Alright! Can you tell me more about what he enjoys during this time of the year?\\ncaller: He loves playing outdoors and making snow forts with his friends.\\nfrosty: In that case, he might be interested in the Tiny Land kids fort building kit. It allows him to create forts both indoors and outdoors, perfect for all seasons.\\ncaller: Great, add both the lola droid and fort building kit to our wish list, please.\\nfrosty: Excellent choices, Mike! I'll add the Star Wars LOLA animatronic droid and the Tiny Land kids fort building kit to your wish list. Have a fantastic holiday season!\\n\"</td>\n",
       "      <td>{\"toy_list\": [\"Star Wars LOLA animatronic droid\", \"Tiny Land kids fort building kit\"], \"location\": \"Los Angeles\"}</td>\n",
       "      <td>EN</td>\n",
       "      <td>968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"\\ncaller: Hello, I'm trying to submit a holiday wish list for my child but I'm not sure where to start.\\nfrosty: Hello and welcome! I'd be happy to help. May I have your name please, and where are you calling from?\\ncaller: My name is Laura, and I'm from Birmingham, England.\\nfrosty: Hi Laura! Nice to meet you. Let's start by discussing some toys that might interest your child. What type of toys do they usually enjoy playing with?\\ncaller: Hmm, I think my child loves playing with dolls and playsets.\\nfrosty: Great! We have a wide variety of dolls and playsets. The baby bee doll and barbie science doll set are popular choices. Why do you think your child might be interested in these types of toys?\\ncaller: My child loves role playing and has a great imagination. She also loves things associated with science and nature.\\nfrosty: I see! In that case, the barbie science doll set could be a great fit. Do you have any special plans to celebrate the holiday season with your family?\\ncaller: Yes, we're planning a family get-together. It's one of our favorite traditions during this time of year.\\nfrosty: That sounds lovely! I also wanted to ask what your favorite holiday memory is?\\ncaller: Back when I was a child, I remember a holiday celebration at my grandparents\\u2019 house. It was a beautiful and magical time.\\nfrosty: What a wonderful memory! Let's narrow down your options. Would you prefer the baby bee doll or the barbie science doll set for your child?\\ncaller: I think my child would enjoy the barbie science doll set more.\\nfrosty: Excellent choice, Laura! So, just to confirm, you\\u2019d like the barbie science doll set for your child's holiday wish list?\\ncaller: Yes, that's right.\\nfrosty: Wonderful! I have noted that down. Thank you for sharing your holiday plans and memories with me, Laura. I hope you and your family have a fantastic time together this holiday season!\\ncaller: Thank you so much, Frosty! I appreciate your help. Have a great day!\\n\"</td>\n",
       "      <td>{\"toy_list\": [\"Barbie Science Lab Playset\"], \"location\": \"Birmingham\"}</td>\n",
       "      <td>EN</td>\n",
       "      <td>527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"frosty: Hi there! I'm Frosty, your cheerful voice bot assistant, and I'm here to help you submit your holiday wish list. What's your name and where are you calling from?\\ncaller: Hey Frosty, I'm Jake and I'm calling from Toronto.\\nfrosty: Nice to meet you, Jake from Toronto! What toys would you like to include in your holiday wish list?\\ncaller: Hmm, I'm not sure yet. I was thinking about getting the Jurassic World dinosaur for my son.\\nfrosty: The Jurassic World Dominion Super Colossal Giganotosaurus is an excellent choice! Would you like some more suggestions based on your son's interests?\\ncaller: Yeah, sure!\\nfrosty: How about the Transformers Rise of the Beasts Beast-Mode Bumblebee? It's perfect for kids who love action and adventure.\\ncaller: Hmm, that sounds interesting. I think he'd love that. Let's add that to the list.\\nfrosty: Alright! What do you enjoy most about this time of the year, Jake?\\ncaller: I love spending time with my family, exchanging gifts, and enjoying nice meals together.\\nfrosty: That's the best part about the holidays! Do you have a favorite pastime or hobby?\\ncaller: I'm a big fan of snowboarding during the winter months. Love hitting the slopes on weekends.\\nfrosty: Sounds like a thrilling adventure! So, I have the Transformers Rise of the Beasts Beast-Mode Bumblebee on your wish list. Is there anything else you'd like to add?\\ncaller: Actually, let's add that Jurassic World dinosaur too. He likes both dinosaurs and Transformers, so I'm sure he'll be happy with either one.\\nfrosty: Perfect! So the Jurassic World Dominion Super Colossal Giganotosaurus will also be added to your list. Have a fantastic holiday season, Jake! Goodbye!\\ncaller: Thanks, Frosty! You too! Goodbye!\"</td>\n",
       "      <td>{\"toy_list\": [\"Transformers Rise of the Beasts Beast-Mode Bumblebee\", \"Jurassic World Dominion Super Colossal Giganotosaurus\"], \"location\": \"Toronto\"}</td>\n",
       "      <td>EN</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"frosty: Welcome to our holiday hotline! My name is Frosty, your friendly voice bot. How can I assist you with your holiday wish list today?\\ncaller: Hello, Frosty! I'd like to submit a holiday wish list for my grandkids. My name is Linda.\\nfrosty: Nice to meet you, Linda! Where are you calling from?\\ncaller: I'm calling from Wellington, New Zealand.\\nfrosty: Wonderful! Now, let's talk about your grandkids' holiday wish list. What items are you considering?\\ncaller: I was thinking about getting them the bluey playhouse and the fingerlings monkey, but I'm open to other suggestions.\\nfrosty: The Bluey Ultimate Lights and Sounds playhouse and the Fingerlings are both popular choices for kids! If you're looking for an interactive pet, how about the Little Live Pets Mama Surprise or the Bitzee interactive pet?\\ncaller: Oh, those sound interesting! Can you tell me more about the Little Live Pets Mama Surprise?\\nfrosty: Absolutely! The Little Live Pets Mama Surprise is an adorable interactive pet with baby surprises concealed inside. Kids will love discovering the baby animals and caring for them, encouraging nurturing play.\\ncaller: That's perfect! Let's add that to the list instead of the fingerlings monkey.\\nfrosty: Great! So, we have the Bluey Ultimate Lights and Sounds playhouse and the Little Live Pets Mama Surprise on your holiday wish list. Is that correct?\\ncaller: Yes, that's correct. Thank you, Frosty!\\nfrosty: You're welcome, Linda! I hope your grandkids enjoy their gifts, and you all have a fantastic holiday season. Goodbye!\\ncaller: Goodbye!\"</td>\n",
       "      <td>{\"toy_list\": [\"Bluey Ultimate Lights and Sounds playhouse\", \"Little Live Pets Mama Surprise\"], \"location\": \"Wellington\"}</td>\n",
       "      <td>EN</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          instruction  \\\n",
       "0  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "1  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "2  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "3  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "4  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               input  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \"frosty: Greetings! I'm Frosty, your voice bot assistant for the holiday season. What's your name?\\ncaller: Hey Frosty, my name is James.\\nfrosty: Hi James! Where are you calling from?\\ncaller: I'm calling from Sydney.\\nfrosty: Nice to meet you, James from Sydney! Let's get started with your holiday wish list. What toy would you like to choose?\\ncaller: Hmm... I'm not sure yet. What do you recommend?\\nfrosty: I'm happy to help you explore our catalog! Does your child like plush toys?\\ncaller: Yes, my little one definitely loves plush toys.\\nfrosty: We have a sweet 2023 Holiday Fox 12-Inch Plush, or how about the Sesame Street Monster Meditation Elmo? Both are soft and cuddly.\\ncaller: Oh, Elmo for sure!\\nfrosty: The Sesame Street Monster Meditation Elmo is an excellent choice. Tell me, what do you enjoy the most about this time of the year?\\ncaller: I love seeing all the decorations and spending time with my family.\\nfrosty: That's wonderful! Do you have any favorite holiday memories?\\ncaller: One year, we had a fantastic snowball fight in the park with our friends. It was so much fun!\\nfrosty: That sounds like a terrific memory! So, are we adding Sesame Street Monster Meditation Elmo to your wish list?\\ncaller: Yes! And you know what? Add the fox plushie as well.\\nfrosty: You got it, adding the 2023 Holiday Fox 12-Inch Plush and Sesame Street Monster Meditation Elmo to your wish list. Have a great holiday season, James!\\ncaller: Thanks, Frosty! You too!\"   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \"caller: Hi there!\\nfrosty: Hello! Welcome to our holiday hotline, I'm Frosty. How can I assist you today?\\ncaller: Hey, Frosty. My name is Mike, and I live in Los Angeles.\\nfrosty: Hi, Mike from Los Angeles! What can I help you with?\\ncaller: I want to submit my holiday wish list, but I'm not sure what toys my son would like.\\nfrosty: No problem! I'd be happy to help you explore our catalog. What are some of his interests?\\ncaller: He loves playing with new gadgets and is a fan of Star Wars.\\nfrosty: How about Star Wars LOLA animatronic droid? It's a fun gadget for any Star Wars fan.\\ncaller: That sounds interesting. What else do you have?\\nfrosty: Another option could be a Dog-E, the robot dog. It's a popular gadget for kids this holiday season.\\ncaller: Let's go with the lola droid. But I also need a second toy.\\nfrosty: Alright! Can you tell me more about what he enjoys during this time of the year?\\ncaller: He loves playing outdoors and making snow forts with his friends.\\nfrosty: In that case, he might be interested in the Tiny Land kids fort building kit. It allows him to create forts both indoors and outdoors, perfect for all seasons.\\ncaller: Great, add both the lola droid and fort building kit to our wish list, please.\\nfrosty: Excellent choices, Mike! I'll add the Star Wars LOLA animatronic droid and the Tiny Land kids fort building kit to your wish list. Have a fantastic holiday season!\\n\"   \n",
       "2  \"\\ncaller: Hello, I'm trying to submit a holiday wish list for my child but I'm not sure where to start.\\nfrosty: Hello and welcome! I'd be happy to help. May I have your name please, and where are you calling from?\\ncaller: My name is Laura, and I'm from Birmingham, England.\\nfrosty: Hi Laura! Nice to meet you. Let's start by discussing some toys that might interest your child. What type of toys do they usually enjoy playing with?\\ncaller: Hmm, I think my child loves playing with dolls and playsets.\\nfrosty: Great! We have a wide variety of dolls and playsets. The baby bee doll and barbie science doll set are popular choices. Why do you think your child might be interested in these types of toys?\\ncaller: My child loves role playing and has a great imagination. She also loves things associated with science and nature.\\nfrosty: I see! In that case, the barbie science doll set could be a great fit. Do you have any special plans to celebrate the holiday season with your family?\\ncaller: Yes, we're planning a family get-together. It's one of our favorite traditions during this time of year.\\nfrosty: That sounds lovely! I also wanted to ask what your favorite holiday memory is?\\ncaller: Back when I was a child, I remember a holiday celebration at my grandparents\\u2019 house. It was a beautiful and magical time.\\nfrosty: What a wonderful memory! Let's narrow down your options. Would you prefer the baby bee doll or the barbie science doll set for your child?\\ncaller: I think my child would enjoy the barbie science doll set more.\\nfrosty: Excellent choice, Laura! So, just to confirm, you\\u2019d like the barbie science doll set for your child's holiday wish list?\\ncaller: Yes, that's right.\\nfrosty: Wonderful! I have noted that down. Thank you for sharing your holiday plans and memories with me, Laura. I hope you and your family have a fantastic time together this holiday season!\\ncaller: Thank you so much, Frosty! I appreciate your help. Have a great day!\\n\"   \n",
       "3                                                                                                                                                                                                                                                             \"frosty: Hi there! I'm Frosty, your cheerful voice bot assistant, and I'm here to help you submit your holiday wish list. What's your name and where are you calling from?\\ncaller: Hey Frosty, I'm Jake and I'm calling from Toronto.\\nfrosty: Nice to meet you, Jake from Toronto! What toys would you like to include in your holiday wish list?\\ncaller: Hmm, I'm not sure yet. I was thinking about getting the Jurassic World dinosaur for my son.\\nfrosty: The Jurassic World Dominion Super Colossal Giganotosaurus is an excellent choice! Would you like some more suggestions based on your son's interests?\\ncaller: Yeah, sure!\\nfrosty: How about the Transformers Rise of the Beasts Beast-Mode Bumblebee? It's perfect for kids who love action and adventure.\\ncaller: Hmm, that sounds interesting. I think he'd love that. Let's add that to the list.\\nfrosty: Alright! What do you enjoy most about this time of the year, Jake?\\ncaller: I love spending time with my family, exchanging gifts, and enjoying nice meals together.\\nfrosty: That's the best part about the holidays! Do you have a favorite pastime or hobby?\\ncaller: I'm a big fan of snowboarding during the winter months. Love hitting the slopes on weekends.\\nfrosty: Sounds like a thrilling adventure! So, I have the Transformers Rise of the Beasts Beast-Mode Bumblebee on your wish list. Is there anything else you'd like to add?\\ncaller: Actually, let's add that Jurassic World dinosaur too. He likes both dinosaurs and Transformers, so I'm sure he'll be happy with either one.\\nfrosty: Perfect! So the Jurassic World Dominion Super Colossal Giganotosaurus will also be added to your list. Have a fantastic holiday season, Jake! Goodbye!\\ncaller: Thanks, Frosty! You too! Goodbye!\"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                            \"frosty: Welcome to our holiday hotline! My name is Frosty, your friendly voice bot. How can I assist you with your holiday wish list today?\\ncaller: Hello, Frosty! I'd like to submit a holiday wish list for my grandkids. My name is Linda.\\nfrosty: Nice to meet you, Linda! Where are you calling from?\\ncaller: I'm calling from Wellington, New Zealand.\\nfrosty: Wonderful! Now, let's talk about your grandkids' holiday wish list. What items are you considering?\\ncaller: I was thinking about getting them the bluey playhouse and the fingerlings monkey, but I'm open to other suggestions.\\nfrosty: The Bluey Ultimate Lights and Sounds playhouse and the Fingerlings are both popular choices for kids! If you're looking for an interactive pet, how about the Little Live Pets Mama Surprise or the Bitzee interactive pet?\\ncaller: Oh, those sound interesting! Can you tell me more about the Little Live Pets Mama Surprise?\\nfrosty: Absolutely! The Little Live Pets Mama Surprise is an adorable interactive pet with baby surprises concealed inside. Kids will love discovering the baby animals and caring for them, encouraging nurturing play.\\ncaller: That's perfect! Let's add that to the list instead of the fingerlings monkey.\\nfrosty: Great! So, we have the Bluey Ultimate Lights and Sounds playhouse and the Little Live Pets Mama Surprise on your holiday wish list. Is that correct?\\ncaller: Yes, that's correct. Thank you, Frosty!\\nfrosty: You're welcome, Linda! I hope your grandkids enjoy their gifts, and you all have a fantastic holiday season. Goodbye!\\ncaller: Goodbye!\"   \n",
       "\n",
       "                                                                                                                                                   output  \\\n",
       "0                                         {\"toy_list\": [\"2023 Holiday Fox 12-Inch Plush\", \"Sesame Street Monster Meditation Elmo\"], \"location\": \"Sydney\"}   \n",
       "1                                       {\"toy_list\": [\"Star Wars LOLA animatronic droid\", \"Tiny Land kids fort building kit\"], \"location\": \"Los Angeles\"}   \n",
       "2                                                                                  {\"toy_list\": [\"Barbie Science Lab Playset\"], \"location\": \"Birmingham\"}   \n",
       "3  {\"toy_list\": [\"Transformers Rise of the Beasts Beast-Mode Bumblebee\", \"Jurassic World Dominion Super Colossal Giganotosaurus\"], \"location\": \"Toronto\"}   \n",
       "4                                {\"toy_list\": [\"Bluey Ultimate Lights and Sounds playhouse\", \"Little Live Pets Mama Surprise\"], \"location\": \"Wellington\"}   \n",
       "\n",
       "  language   id  lang_label  \n",
       "0       EN  245           0  \n",
       "1       EN  968           0  \n",
       "2       EN  527           0  \n",
       "3       EN  105           0  \n",
       "4       EN  999           0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79793829-d70f-4bed-93b2-1a4db2fbfaea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': Dataset.from_pandas(train_df),\n",
    "    'eval': Dataset.from_pandas(eval_df),\n",
    "    'test': Dataset.from_pandas(test_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb080d-a35e-4629-88d9-46c1d97c90dd",
   "metadata": {},
   "source": [
    "### Apply Prompt to Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e684e33f-d7db-4418-bab5-c3d490067fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "<</SYS>>\n",
    "### Instruction:\n",
    "{{instruction}}\n",
    "### Input:\n",
    "{{input_}}\n",
    "### Output:\n",
    "{{output}}\n",
    "{{eos_token}}\n",
    "\"\"\"\n",
    "\n",
    "eval_prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "<</SYS>>\n",
    "### Instruction:\n",
    "{{instruction}}\n",
    "### Input:\n",
    "{{input_}}\n",
    "### Output:\n",
    "{{eos_token}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ff73e9-780a-44cd-b792-e351a9601f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d15726bd504ee79a9f3fa150f1d63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee67b16331ad4ce4ab07e17ef6cf6076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ccdb3d3667434485d66776fe7072ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_train_template(sample):\n",
    "    return {\n",
    "        \"text\": train_prompt.format(\n",
    "            instruction=sample[\"instruction\"],\n",
    "            input_=sample[\"input\"].replace('\\\\n', '\\n'),\n",
    "            output=sample[\"output\"],\n",
    "            eos_token=tokenizer.eos_token,\n",
    "        )\n",
    "    }\n",
    "\n",
    "def apply_eval_template(sample):\n",
    "    return {\n",
    "        \"text\": eval_prompt.format(\n",
    "            instruction=sample[\"instruction\"],\n",
    "            input_=sample[\"input\"].replace('\\\\n', '\\n'),\n",
    "            eos_token=tokenizer.eos_token,\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "#applying template\n",
    "\n",
    "datasets['train'] = datasets['train'].map(apply_train_template, remove_columns=list(datasets['train'].features))\n",
    "for k in ['eval', 'test']:\n",
    "    datasets[k] = datasets[k].map(apply_eval_template, remove_columns=list(datasets[k].features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac551d54-0591-43bc-a96a-da5edd3aa565",
   "metadata": {},
   "source": [
    "### Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2290f191-ba23-4b83-8653-3d9c97d512cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce26d67eefc54a268adebeb4d0316435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56992c8b452d4718a908a1ef87fb6923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea977bebb8a84f3dab4e386b766ed362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2882a73ace14c6f8dec83f86619d79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ee5f0087be4900a9feab01f0f619cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6ab7c39414458681042e4c597519e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in datasets.items():\n",
    "    datasets[k] = v.map(\n",
    "        lambda sample: tokenizer(sample[\"text\"]),\n",
    "        batched=True,\n",
    "        remove_columns=list(v.features),\n",
    "    ).map(Concatenator(), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88447074-21a8-433a-a937-a3e3514650c4",
   "metadata": {},
   "source": [
    "## Fine-tune Llama 2 Model\n",
    "\n",
    "\n",
    "Fine-tuning is one form of model training. We start training from a pre-trained model and adjust a set of model parameters to better solve for a concrete task based on task specific data. Today we are going to fine-tune 7B Llama 2 model using LoRA (Low-Rank Adaptation)--which is a parameter efficient way of fine-tuning LLM. \n",
    "\n",
    "Instead of adjusting all the ~7B parameters, LoRA allows us to adjust only a percent of model weights--which can save compute and memory resources dramatically. For this lab, we will fine-tune our model using LoRA on a single A10 GPU. This will demostrate how good the inference can be on fine-tuned models even with limited compute.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "We're passing `train_dataset` and `eval_dataset` that are used to generate loss calculation during fine-tuning process and we've set `output_weights_dir` as the directory where the fine-tuned weights will be stored after fine-tuning job completes.\n",
    "\n",
    "We're also setting `max_steps=1` with 4bit quantization. Quantization is required to train on single A10 GPU. To achieve good performance for the task, you will need at least 1 `num_epochs`, feel free to explore this on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba1f466-d668-4f68-9d8d-ea7367b0369d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "#setting the model into training mode\n",
    "model.train()\n",
    "\n",
    "#setting up training\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_kbit_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b15d38d4-c399-4daa-9771-df29edf8c3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rm -r output_weights_dir # deletes prior fine tuning weights\n",
    "!mkdir output_weights_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328c128c-5321-4132-a9b6-da362f62790c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"output_weights_dir\"\n",
    "enable_profiler = False\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 1,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674205dc-ded7-45eb-9450-a767ae5cfe85",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4188f41a-0513-4848-aab6-fb0226d557f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.181, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='83' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [83/83 22:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.377400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.994500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.892900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.791100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profiler = nullcontext() \n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets['train'],\n",
    "        eval_dataset=datasets['eval'],\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "    \n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8f68f-9a80-403e-8d5c-ff02d9287d05",
   "metadata": {},
   "source": [
    "## Return to Local Jupyter Lab\n",
    "\n",
    "we have finished fine tuning and will now return to our local jupyter lab environment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
