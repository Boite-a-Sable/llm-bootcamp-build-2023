{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps --force-reinstall snowflake_ml_python-1.0.12-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install peft transformers==4.34.0 tokenizers vllm==0.2.1.post1 bitsandbytes datasets absl-py==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Set your Hugging Face token\n",
    "!huggingface-cli login --token "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.model.models import llm\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "import snowflake.ml.playground.finetune as ft_util\n",
    "from snowflake.snowpark import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "logger = logging.getLogger(\"snowflake.ml\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Secure Connection\n",
    "\n",
    "*NOTE: Update [connection.json](connection.json) and set your password, Hugging Face token, and replace '####' with your user number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Llama 2 in Snowpark Container Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training Dataset\n",
    "\n",
    "*NOTE: Fine-tuning using 100 records on this setup (compute and other resources) will take about ~5mins.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"transcripts.json\", lines=True)\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "train_df = df.head(100)\n",
    "print(f\"Train        : {train_df.shape[0]}\")\n",
    "eval_df = df[200:300]\n",
    "print(f\"Eval         : {eval_df.shape[0]}\")\n",
    "test_df = df.tail(100)\n",
    "print(f\"Test         : {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune Llama 2 Model\n",
    "\n",
    "Fine-tuning is one form of model training. We start training from a pre-trained model and adjust a set of model parameters to better solve for a concrete task based on task specific data. Today we are going to fine-tune 7B Llama 2 model using LoRA (Low-Rank Adaptation)--which is a parameter efficient way of fine-tuning LLM. \n",
    "\n",
    "Instead of adjusting all the ~7B parameters, LoRA allows us to adjust only a percent of model weights--which can save compute and memory resources dramatically. For this lab, we will fine-tune our model using LoRA on a single A10 GPU. This will demostrate how good the inference can be on fine-tuned models even with limited compute.\n",
    "\n",
    "##### Configuration\n",
    "\n",
    "We're passing `train_dataset` and `eval_dataset` that are used to generate loss calculation during fine-tuning process and we've set `output_weights_dir` as the directory where the fine-tuned weights will be stored after fine-tuning job completes.\n",
    "\n",
    "We're also setting `max_steps=1` with 4bit quantization. Quantization is required to train on single A10 GPU. To achieve good performance for the task, you will need at least 1 `num_epochs`, feel free to explore this on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir merged_weights_dir\n",
    "!mkdir output_weights_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# NOTE: Fine-tuning using 100 records on this setup (compute and other resources) will take about ~5mins.\n",
    "\n",
    "merged_weights_dir = 'merged_weights_dir'\n",
    "output_weights_dir = 'output_weights_dir'\n",
    "\n",
    "runner = ft_util.FinetuneModelRunner(\n",
    "    base_model_id=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    task_type=ft_util.FinetuneTaskType.INSTRUCT,\n",
    "    train_dataset=train_df,\n",
    "    eval_dataset=eval_df,\n",
    ")\n",
    "\n",
    "mcf = ft_util.ModelConfig(\n",
    "    max_steps=1,\n",
    "    quantization=ft_util.QuantizationConfig(\n",
    "        k_bits=4,\n",
    "    ),\n",
    "    merged_weights_dir_path=merged_weights_dir,\n",
    ")\n",
    "\n",
    "_ = runner.train(output_weights_dir, model_cfg=mcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Results on Eval Dataset\n",
    "\n",
    "After the fine-tuning job completes, we call `get_eval_results`, this will run evaluation and get model predictions using the entire `eval_dataset`. You can see the output by model in the `predicted` column of the dataframe.\n",
    "\n",
    "*Examine the \"output\" and \"predicted\" columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = runner.get_eval_results()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on Custom Transcript\n",
    "\n",
    "Additionally, you may want to manually craft some cases to test the boundaries of the model. To do that, you can use the `infer` method to run prediction against a single sample interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.infer(\n",
    "     {\n",
    "    'instruction': \"\"\"\n",
    "        \"Extract JSON response with 'location' and 'toy_list' as keys. 'location': \n",
    "        Location of the caller. Include city only.'toy_list': List of toy names from the caller.\"\n",
    "    \"\"\",\n",
    "    'input': \"\"\"\n",
    "        \"frosty: Hello, hello! Who's ready to chat with Frosty today?\\ncaller: Hi, I'm Dustin from Cape Town, South Africa.\\nfrosty: \n",
    "        Hi Dustin, it's awesome to meet you! Do you already know what you would like for your holiday gift?\\ncaller: \n",
    "        Yeah, I think I want the ninja turtles delivery van, or maybe the robot dog. \n",
    "        I can't decide...\\nfrosty: Both sound like entertaining choices! \n",
    "        Why are you interested in these particular toys?\\ncaller: The ninja turtles van is so cool! And the robot dog, it's like a pet you don't have to clean up after.\\nfrosty: \n",
    "        That's true! Savage choices, Dustin! How do you usually celebrate the holiday season?\\ncaller: \n",
    "        We usually have a big family barbeque and play games all day long.\\nfrosty: Sounds fun! What is your favorite thing about this time of year?\n",
    "        \\ncaller: I like that everyone is happy and I get to spend a lot of time with my family.\n",
    "        \\nfrosty: That's wonderful! So Dustin, have you thought any more about your holiday wish?\n",
    "        \\ncaller: I think I'm going to get the robot dog. It sounds fun and I won't have to walk it.\n",
    "        \\nfrosty: That's a clever choice, Dustin! I hope you have a fantastic holiday season!\"\n",
    "\"\"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Inference on Test Dataset\n",
    "\n",
    "For batch inference to test on a holdout dataset, you can use `infer_batch` on a dataframe.\n",
    "\n",
    "*Examine the \"output\" and \"predicted\" columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_res = runner.infer_batch(test_df)\n",
    "test_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log and Deploy Fine-tuned Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"LLAMA2_7b_CHAT\"\n",
    "MODEL_VERSION = \"FineTunedV1.0\"\n",
    "DEPLOYMENT_NAME = \"FINETUNED_LLAMA2\"\n",
    "MODEL_REGISTRY_DB = connection_parameters['database']\n",
    "MODEL_REGISTRY_SCHEMA = connection_parameters['schema']\n",
    "COMPUTE_POOL = connection_parameters['compute_pool']\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=MODEL_REGISTRY_DB, \n",
    "    schema_name=MODEL_REGISTRY_SCHEMA, \n",
    "    create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete any existing deployments and models from in Snowpark registry to avoid resource contention during this bootcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registry.list_deployments(model_name=MODEL_NAME,model_version=MODEL_VERSION).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# registry.delete_deployment(model_name=MODEL_NAME,model_version=MODEL_VERSION,deployment_name=DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# registry.delete_model(model_name=MODEL_NAME,model_version=MODEL_VERSION,delete_artifact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log and Deploy Fine-tuned Llama 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Logging and deploying fine-tuned model on this setup (compute and other resources) will take about ~15mins\n",
    "- Notice that the \"model_id_or_path\" is set to the output weights folder `output_weights_dir` where the weights from fine-tuning the model are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "options = llm.LLMOptions(\n",
    "    token=connection_parameters[\"huggingface_token\"],\n",
    "    max_batch_size=100,\n",
    ")\n",
    "\n",
    "llama_model = llm.LLM(\n",
    "    model_id_or_path=output_weights_dir,\n",
    "    options=options\n",
    ")\n",
    "\n",
    "llama_model_ref = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model\n",
    ")\n",
    "\n",
    "llama_model_ref.deploy(\n",
    "    deployment_name=DEPLOYMENT_NAME, \n",
    "    platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    permanent=True, \n",
    "    options={\"compute_pool\": COMPUTE_POOL, \"num_gpus\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Eval Dataset with Specific Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] <<SYS>>\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "<</SYS>>\n",
    "### Instruction:\n",
    "Extract JSON response with 'location' and 'toy_list' as keys.\n",
    "'location': Location string of the caller.\n",
    "'toy_list': List of toy names from the caller.\n",
    "### Input:\n",
    "\n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "eval_df['input'] = begin_prompt + eval_df['input'] + end_prompt\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "eval_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on Eval Dataset using fine-tuned Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_model_ref.predict(deployment_name=DEPLOYMENT_NAME,data=eval_df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run Inference in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Go to Snowsight and run the following commands in a SQL Worksheet\n",
    "\n",
    "# create or replace function build_prompt(inp varchar)\n",
    "# returns varchar\n",
    "# language sql\n",
    "# as $$\n",
    "#     '[INST] <<SYS>>\\n' ||\n",
    "#     'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n' ||\n",
    "#     '<</SYS>>\\n' ||\n",
    "#     '### Instruction:\\n' ||\n",
    "#     'Extract JSON response with \\'location\\' and \\'toy_list\\' as keys.\\n' ||\n",
    "#     '\\'location\\': Location of the caller. Include city only.\\n' ||\n",
    "#     '\\'toy_list\\': List of toy names from the caller.\\n' ||\n",
    "#     '### Input:\\n' ||\n",
    "#     '\"' || inp || '\"\\n' ||\n",
    "#     '[/INST]'\n",
    "# $$;\n",
    "\n",
    "# SELECT TRAINED_LLAMA2(object_construct('input', build_prompt(select transcript from frosty_transcripts limit 1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Up Resources\n",
    "\n",
    "Delete deployment and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_model_ref.delete_deployment(deployment_name=DEPLOYMENT_NAME)\n",
    "llama_model_ref.delete_model(delete_artifact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
